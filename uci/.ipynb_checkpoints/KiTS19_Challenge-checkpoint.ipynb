{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-YgPcuHiRtI5"
   },
   "source": [
    "# Overview\n",
    "\n",
    "In this exercise, we will be performing analysis on CT examinations of the abdomen performed in patients with renal carcinoma (e.g. kidney cancer). Our goal with be to perform a few simple preprocessing steps in preparation for training a machine learning algorithm. The data for this exercise is a small sample from the KiTS 2019 MICCAI Challenge (https://kits19.grand-challenge.org/home/).\n",
    "\n",
    "## Data\n",
    "\n",
    "We will begin by downloading the data, and taking a look at some of its organization here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WW5PwkZnRPRr"
   },
   "outputs": [],
   "source": [
    "# --- Download the data\n",
    "!wget -O ex1.zip \"https://www.dropbox.com/s/v2f14er8yku0wwf/ex1.zip?dl=1\"\n",
    "!mkdir /data\n",
    "!unzip -o ex1.zip -d /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wmoUQtOTs5aA"
   },
   "outputs": [],
   "source": [
    "# --- List directory contents\n",
    "!ls -al /data/ex1\n",
    "\n",
    "# --- List contents of a single folder\n",
    "!ls -al /data/ex1/case_00010/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKEHXh0Hv2Ym"
   },
   "source": [
    "The raw data we will be using in the exercise are 3D CT scan volumes of the abdomen. The data is stored as a 4D array of size: \"Z\" by \"Y\" by \"X\" by 1 (e.g. the fourth \"dimension\" is always one for this particular dataset). This format, while a bit unusual, is the default order used by most machine learning libraries such as Tensorflow. Let's take a look here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTMmjHa5S8BQ"
   },
   "outputs": [],
   "source": [
    "# --- Use NumPy to load data files\n",
    "import numpy as np\n",
    "\n",
    "# --- Note that the data consists of 4D volumes\n",
    "dat = np.load('/data/ex1/case_00010/dat.npy')\n",
    "print(type(dat))\n",
    "print(dat.shape)\n",
    "\n",
    "# --- Load corresponding voxel sizes\n",
    "dim = np.load('/data/ex1/case_00010/dim.npy')\n",
    "print(type(dim))\n",
    "print(dim.shape)\n",
    "print(dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LLg5TGW6wZlj"
   },
   "source": [
    "## Visualization\n",
    "\n",
    "At various points of this exercise, it will be crucial to visualize the data. To do so, feel free to use this simple method to show any given single slice of the 3D volume (of course you may add and/or embellish this method as you like)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E8bdbvDUhAx_"
   },
   "outputs": [],
   "source": [
    "# --- Visualize using pylab\n",
    "import pylab\n",
    "\n",
    "def show_2d(im, title=None, figsize=(7, 7)):\n",
    "    \"\"\"\n",
    "    Method to show 2D image \n",
    "    \n",
    "    \"\"\"\n",
    "    pylab.figure(figsize=figsize)\n",
    "    pylab.axis('off')\n",
    "    pylab.imshow(np.squeeze(im), cmap=pylab.cm.gist_gray, vmin=-240, vmax=240)\n",
    "    \n",
    "    if title is not None:\n",
    "        pylab.title(title)\n",
    "\n",
    "# --- Show the 25th \"slice\" of the dat volume\n",
    "show_2d(dat[25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nAxuQGp7V2xj"
   },
   "source": [
    "## Voxel Size and Orientation\n",
    "\n",
    "Each 3D \"pixel\" in our volume matrix is known as a **voxel**. Voxels have a size (in mm) in each Z, Y and X dimension. In our particular dataset, based on acquisition parameters, the image volumes are isotropic in the XY-plane (e.g. the X and Y voxel sizes are the same) but different in the Z-axis. \n",
    "\n",
    "Voxel size is an important consideration when re-orienting (e.g. flipping) the raw volume matrices into different planes. More specifically in the world of medical imaging, the same data volume can be viewed in three dominant orientations: axial, coronal and sagittal.\n",
    "\n",
    "See diagram here:\n",
    "\n",
    "![Orientation](https://upload.wikimedia.org/wikipedia/commons/thumb/0/03/Human_anatomy_planes%2C_labeled.jpg/220px-Human_anatomy_planes%2C_labeled.jpg)\n",
    "\n",
    "Note the following conventions:\n",
    "\n",
    "* Z-axis = up-down axis\n",
    "* Y-axis = forward-backward axis\n",
    "* X-axis = left-right axis\n",
    "* XY-plane = axial\n",
    "* ZX-plane = coronal\n",
    "* ZY-plane = sagittal\n",
    "\n",
    "Because of differences in voxel size in the three planes, if we naively rotate our image matrix in the three planes, the images will look *normal* in the XY plane only but *distorted* in the ZY or ZX planes.\n",
    "\n",
    "See examples here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F3awDLRkXzug"
   },
   "outputs": [],
   "source": [
    "# --- Axial image (normal)\n",
    "axi = dat[25]\n",
    "show_2d(axi, 'orient = axial')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i44Odo2myLlE"
   },
   "outputs": [],
   "source": [
    "# --- Coronal image (distorted/compressed)\n",
    "cor = dat[:, 256]\n",
    "show_2d(cor, 'orient = coronal')\n",
    "print(cor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsUf4440yMBv"
   },
   "outputs": [],
   "source": [
    "# --- Sagittal image (distorted/compressed)\n",
    "sag = dat[:, :, 256]\n",
    "show_2d(sag, 'orient = sagittal')\n",
    "print(sag.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cscjt5nMX8N3"
   },
   "source": [
    "To correct this distortion, we would need to resample (zoom) the volume as shown here while **accounting for voxel size**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mxl2mcFAYB5P"
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "# --- Calculate ratio of isotropic image\n",
    "zoom = [dim[0] / dim[1], 1, 1]\n",
    "\n",
    "# --- Resample to isotropic\n",
    "print('Before zoom: ', cor.shape)\n",
    "cor_ = ndimage.zoom(cor, zoom=zoom, order=1)\n",
    "print('After zoom:', cor_.shape)\n",
    "\n",
    "# --- Show new image\n",
    "show_2d(cor_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dXmWWFrEzbVx"
   },
   "source": [
    "Much better! Now that we have accounted for the differences in voxel size, we have properly \"uncompressed\" our coronal image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qui55-1hTDPY"
   },
   "source": [
    "# Exercise 1\n",
    "\n",
    "CT scans of the abdomen are highly varied with regards to field of view and patient positioning. Thus, the first part of this algorithm is to generate bounding cube crops of the right and left hemi-abdomen (e.g. each containing the right and left kidney, respectively). By standardizing the field of view, these cropped volumes will make it much easier for our downstream deep learning networks to perform subsequent localization and classification tasks.\n",
    "\n",
    "## Resampling\n",
    "\n",
    "To begin, let us resample all of our 3D volumes into a uniform shape. You will notice that all of our raw CT volumes are of different matrix shapes. To train our algorithm we need to resample our data to a uniform 256 x 256 x 256 (Z x Y x X) shape. Importantly the cube volume must also be **isotropic**, in other words the same **voxel size** in all the dimensions, with no distortion in any plane.\n",
    "\n",
    "Based on this, the first task to perform is the following: given an arbitrary 3D image volume of shape Z x Y x X, and corresponding voxel dimensions in each direction (in mm), write an algorithm to generate a fixed 256 x 256 x 256 cube with the **same voxel size** in each direction. Try to keep the algorithm as generic as possible---in our three examples, the Z- voxel size is always larger than the X-/Y- voxel size (and the X-/Y- voxel sizes are the same) but do not assume that this is always the case. As needed, you may pad the original volume with zeros in up to **two dimensions** (if you need to pad in all three directions then reduce the padding in all directions until at least one dimension does not need to be padded anymore).\n",
    "\n",
    "Write your final algorithm by filling in the method below; feel free to use additional code blocks as needed to test and brainstorm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pbe2q95GVFMg"
   },
   "outputs": [],
   "source": [
    "def resample_to_256_cube(vol, dims):\n",
    "    \"\"\"\n",
    "    Method to resample provided volume to 3D isotropic 256 x 256 x 256 matrix\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (np.ndarray) vol  : a 4D matrix of size Z * Y * X * 1\n",
    "      (np.ndarray) dims : a 3-element vector of voxel size (in mm)\n",
    "      \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6M9O4DE1VGHa"
   },
   "source": [
    "# Exercise 2\n",
    "\n",
    "Now that we have 256 x 256 x 256 cubes, we can train a CNN algorithm to generate the desired 3D crops extending along the boundaries of the right and left hemi-abdomen. The following images show examples of the final desired right- and left- crops in the axial, coronal and sagittal planes: \n",
    "\n",
    "## Crops (axial plane)\n",
    "\n",
    "![axial](https://raw.githubusercontent.com/CAIDMRes/kits_test/master/pngs/kits_axi.png)\n",
    "\n",
    "## Crops (coronal plane)\n",
    "\n",
    "![coronal](https://raw.githubusercontent.com/CAIDMRes/kits_test/master/pngs/kits_cor.png)\n",
    "\n",
    "## Crops (sagittal plane)\n",
    "\n",
    "![sagittal](https://raw.githubusercontent.com/CAIDMRes/kits_test/master/pngs/kits_sag.png)\n",
    "\n",
    "\n",
    "\n",
    "To generate these 3D bounding cube crops, we will train a 2D slice-by-slice CNN binary classifier to determine whether any given \"slice\" of data contains **any portion** of the region of interest shown above. For example in the axial plane, the algorithm would return a prediction of 1 (True) if the slice is at a level that includes any part of the hemi-abdomen (green region) and a prediction of 0 (False) if the slice is at a level above (e.g. lungs) or below ( e.g. pelvis) the region of interest. The same type of information will also be returned by feeding in slices from any of the three orthogonal planes. Because our input volume is a 256 x 256 x 256 cube, a series of predictions along any given single plane can be represented as a 256-element vector.\n",
    "\n",
    "Let us download and look at some example data here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prS39Si7fKVO"
   },
   "outputs": [],
   "source": [
    "# --- Download additional data\n",
    "!wget -O ex2.zip \"https://www.dropbox.com/s/sseq8g00ebni6iz/ex2.zip?dl=1\"\n",
    "!unzip -o ex2.zip -d /data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gtK0e3iil8X9"
   },
   "outputs": [],
   "source": [
    "# --- List directory contents\n",
    "!ls -al /data/ex2\n",
    "\n",
    "# --- List contents of a single folder\n",
    "!ls -al /data/ex2/case_00214/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cFGnyPBNZyZK"
   },
   "outputs": [],
   "source": [
    "# --- Load remaining data\n",
    "dat = np.load('/data/ex2/case_00214/dat.npy')\n",
    "print(type(dat))\n",
    "print(dat.shape)\n",
    "\n",
    "# --- Load corresponding prediction vectors\n",
    "pred_axi = np.load('/data/ex2/case_00214/pred_axi.npy')\n",
    "pred_cor = np.load('/data/ex2/case_00214/pred_cor.npy')\n",
    "pred_sag = np.load('/data/ex2/case_00214/pred_sag.npy')\n",
    "\n",
    "print(type(pred_axi))\n",
    "print(pred_axi.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Q6SNcP_nf4xS"
   },
   "source": [
    "Using this data, the second task to perform is the following: given three perpendicular prediction vectors (each of size 256), generate a final 3D mask (256 x 256 x 256) corresponding to the two areas of interest shown above. The mask you create should be binary (e.g. 1 = region of interest, 0 = background), and should delineate the two ROIs for the right and left hemi-abdomen.\n",
    "\n",
    "**Important**: Note that the prediction vectors are generated by a CNN, and thus will have a degree of noise. In other words, occassionally there will be false positive and false negative predictions. Therefore as needed you may postprocess the prediction vectors so that the two most dominant areas of interest are properly identified.\n",
    "\n",
    "As an example, see sagittal prediction below---while there are two \"dominant\" areas, occasionally there is a mistake (~5%) in the algorithm prediction. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VH6W8C12m3er"
   },
   "outputs": [],
   "source": [
    "print(pred_sag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gNAKY1bcm3_6"
   },
   "source": [
    "Write your final algorithm by filling in the method below. Feel free to test your algorithm by overlaying the mask on your original volumes and visualizing. Your final results should be similar to the ROIs shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TYccJLgdgGep"
   },
   "outputs": [],
   "source": [
    "def create_cube_mask(pred_axi, pred_cor, pred_sag):\n",
    "    \"\"\"\n",
    "    Method to generate 3D mask of the R-/L- hemiabdomen using orthogonal \n",
    "    prediction vectures generated by a CNN.\n",
    "    \n",
    "    :params\n",
    "    \n",
    "      (np.ndarray) pred_axi : 256-element prediction vector in the axial plane\n",
    "      (np.ndarray) pred_cor : 256-element prediction vector in the coronal plane\n",
    "      (np.ndarray) pred_sag : 256-element prediction vector in the sagittal plane\n",
    "      \n",
    "    :return\n",
    "    \n",
    "      (np.ndarray) mask : 3D binary mask of size 256 x 256 x 256 contained the \n",
    "                          filled two dominant ROIs\n",
    "\n",
    "    \"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "KiTS19_Challenge.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
