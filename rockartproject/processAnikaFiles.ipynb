{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mammoth\n",
    "from IPython.core.display import display, HTML\n",
    "import subprocess\n",
    "import os\n",
    "import glob\n",
    "import string\n",
    "import stat\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from difflib import SequenceMatcher\n",
    "import shutil \n",
    "import filecmp\n",
    "import difflib\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT THE DOC AND DOCX FILES\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.docx\"\n",
    "allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.doc\"\n",
    "allFilesDoc = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "print(\"doc: %s\\ndocx: %s\" % (str(len(allFilesDoc)), str(len(allFilesDocx))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# CONVERT FROM DOC TO DOCX SO MAMMOTH CAN CONVERT TO HTML\n",
    "\n",
    "docFilesConverted = []\n",
    "for i,filename in enumerate(allFilesDoc):\n",
    "    if i % 100 == 0:\n",
    "        print(i)\n",
    "    os.chdir('/'.join(filename.split('/')[0:-1]))\n",
    "    if filename.endswith('.doc'):\n",
    "        docFilesConverted.append(filename)\n",
    "        subprocess.call(['/Applications/LibreOffice.app/Contents/MacOS/soffice', '--headless', '--convert-to', 'docx', filename])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COUNT THE DOC AND DOCX FILES\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.docx\"\n",
    "allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.doc\"\n",
    "allFilesDoc = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "print(\"doc: %s\\ndocx: %s\" % (str(len(allFilesDoc)), str(len(allFilesDocx))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.docx\"\n",
    "allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "numFile = len(allFilesDocx)\n",
    "\n",
    "for i in range(10):\n",
    "    os.mkdir(\"/Users/mettinger/Desktop/rockArtProjectData/anikaDocx\" + str(i))\n",
    "    \n",
    "for i,filePath in enumerate(allFilesDocx):\n",
    "    fileName = filePath.split(\"/\")[-1]\n",
    "    index = str(int( (i * 10) / numFile))\n",
    "    destPath = \"/Users/mettinger/Desktop/rockArtProjectData/anikaDocx\" + index + \"/\" + fileName\n",
    "    shutil.copyfile(filePath, destPath)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE TILDA FILES\n",
    "\n",
    "allTildaFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/~*.docx\"\n",
    "allTildaFiles = glob.glob(allTildaFilesGlob, recursive=True)\n",
    "\n",
    "for thisFile in allTildaFiles:\n",
    "    os.remove(thisFile)\n",
    "print(\"tilda removed: \" + str(len(allTildaFiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND IDENTICAL FILES\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.docx\"\n",
    "allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "print(len(allFilesDocx))\n",
    "\n",
    "identicalDict = {}\n",
    "\n",
    "for i,filename in enumerate(allFilesDocx):\n",
    "    flag = False\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for thisKey in identicalDict.keys():\n",
    "        if filecmp.cmp(thisKey, filename):\n",
    "            identicalDict[thisKey].append(filename)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        identicalDict[filename] = []\n",
    "        \n",
    "print(\"repeated files: \" + str(sum([len(value) for key,value in identicalDict.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE IDENTICAL FILES\n",
    "\n",
    "for thisKey in identicalDict.keys():\n",
    "    thisFileList = identicalDict[thisKey]\n",
    "    for thisFile in thisFileList:\n",
    "        os.remove(thisFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IDENTICAL DOCX FILES HAVE BEEN ELIMINATED\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.docx\"\n",
    "allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "print(len(allFilesDocx))\n",
    "\n",
    "identicalDict = {}\n",
    "\n",
    "for i,filename in enumerate(allFilesDocx):\n",
    "    flag = False\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for thisKey in identicalDict.keys():\n",
    "        if filecmp.cmp(thisKey, filename):\n",
    "            identicalDict[thisKey].append(filename)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        identicalDict[filename] = []\n",
    "        \n",
    "print(\"repeated files: \" + str(sum([len(value) for key,value in identicalDict.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripInfo(soup):\n",
    "    regExpList = [r'Coffman', r'149 Atlantic',r'Swampscott',r'\\$\\d*\\.\\d\\d']\n",
    "    for thisRegExp in regExpList:\n",
    "        for elem in soup(text=re.compile(thisRegExp)):\n",
    "            elem.parent.decompose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CONVERT TO HTML, DELETE SENSITIVE INFORMATION (ADDRESS, ORDER INFO, ETC....), SAVE HTML FILE\n",
    "\n",
    "allDocFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.docx\"\n",
    "allFiles = glob.glob(allDocFilesGlob, recursive=True)\n",
    "convertErrors = []\n",
    "regExErrors = []\n",
    "writeErrors = []\n",
    "print(len(allFiles))\n",
    "\n",
    "for i,filename in enumerate(allFiles):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    with open(filename, \"rb\") as docx_file:\n",
    "        try:\n",
    "            result = mammoth.convert_to_html(docx_file)\n",
    "            html = result.value\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "            try:\n",
    "                stripInfo(soup)\n",
    "                html = str(soup)\n",
    "                try:\n",
    "                    thisFileName = filename[0:-5] + \".html\"\n",
    "                    with open(thisFileName, \"w\") as thisHtmlFile:\n",
    "                        thisHtmlFile.write(str(html))\n",
    "                except:\n",
    "                    writeErrors.append(filename)\n",
    "            except:\n",
    "                regExErrors.append(filename)\n",
    "        except:\n",
    "            convertErrors.append(filename)\n",
    "    \n",
    "len(writeErrors), len(regExErrors), len(convertErrors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FIND IDENTICAL HTML FILES\n",
    "\n",
    "allFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.html\"\n",
    "allFiles = glob.glob(allFilesGlob, recursive=True)\n",
    "print(len(allFiles))\n",
    "\n",
    "identicalDict = {}\n",
    "\n",
    "for i,filename in enumerate(allFiles):\n",
    "    flag = False\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for thisKey in identicalDict.keys():\n",
    "        if filecmp.cmp(thisKey, filename):\n",
    "            identicalDict[thisKey].append(filename)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        identicalDict[filename] = []\n",
    "        \n",
    "print(\"repeated files: \" + str(sum([len(value) for key,value in identicalDict.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE IDENTICAL HTML FILES AND CORRESPONDING DOCX FILES\n",
    "\n",
    "htmlRemoveErrors = []\n",
    "docxRemoveErrors = []\n",
    "\n",
    "for thisKey in identicalDict.keys():\n",
    "    thisFileList = identicalDict[thisKey]\n",
    "    for thisFile in thisFileList:\n",
    "        thisDocxFile = thisFile[0:-5] + \".docx\"\n",
    "        \n",
    "        try:\n",
    "            os.remove(thisFile)\n",
    "        except:\n",
    "            htmlRemoveErrors.append(thisFile)\n",
    "        try:\n",
    "            os.remove(thisDocxFile)\n",
    "        except:\n",
    "            docxRemoveErrors.append(thisDocxFile)\n",
    "            \n",
    "len(htmlRemoveErrors), len(docxRemoveErrors)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK IDENTICAL HTML FILES HAVE BEEN ELIMINATED\n",
    "\n",
    "allFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.html\"\n",
    "allFiles = glob.glob(allFilesGlob, recursive=True)\n",
    "print(len(allFiles))\n",
    "\n",
    "identicalDict = {}\n",
    "\n",
    "for i,filename in enumerate(allFiles):\n",
    "    flag = False\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for thisKey in identicalDict.keys():\n",
    "        if filecmp.cmp(thisKey, filename):\n",
    "            identicalDict[thisKey].append(filename)\n",
    "            flag = True\n",
    "            break\n",
    "    if not flag:\n",
    "        identicalDict[filename] = []\n",
    "        \n",
    "print(\"repeated files: \" + str(sum([len(value) for key,value in identicalDict.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURE TO DETECT DUPLICATES AND NEAR DUPLICATES\n",
    "\n",
    "allFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.html\"\n",
    "allFiles = glob.glob(allFilesGlob, recursive=True)\n",
    "print(len(allFiles))\n",
    "\n",
    "simHTMLList = []\n",
    "\n",
    "for i,firstPath in enumerate(allFiles):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    for j in range(i+1, len(allFiles)):\n",
    "        secondPath = allFiles[j]\n",
    "        score = SequenceMatcher(None, firstPath, secondPath).ratio()\n",
    "        if score > .9:\n",
    "            simHTMLList.append((firstPath, secondPath, score))\n",
    "        \n",
    "simHTMLList = sorted(simHTMLList, key = lambda x: x[2], reverse = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simHTMLList[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "htmlFile1, htmlFile2, simScore = simHTMLList[20]\n",
    "\n",
    "with open(htmlFile1, 'r') as fp:\n",
    "    html1 = fp.readlines()[0]\n",
    "    \n",
    "with open(htmlFile2, 'r') as fp:\n",
    "    html2 = fp.readlines()[0]\n",
    "\n",
    "print(htmlFile1)\n",
    "print(htmlFile2)\n",
    "print(simScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(html1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(HTML(html2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MEASURE SIMILARITY OF ALL FILENAMES TO DETECT DUPLICATES AND NEAR DUPLICATES\n",
    "\n",
    "allFilesGlob = \"/Users/mettinger/Desktop/rockArtProjectData/**/*.html\"\n",
    "allFiles = glob.glob(allFilesGlob, recursive=True)\n",
    "print(len(allFiles))\n",
    "\n",
    "simNameList = []\n",
    "\n",
    "for i in range(len(allFiles)):\n",
    "    if i % 1000 == 0:\n",
    "        print(i)\n",
    "    firstPath = allFiles[i]\n",
    "    firstName = firstPath.split('/')[-1].split('.')[0]\n",
    "    for j in range(i + 1, len(allFiles)):\n",
    "        secondPath = allFiles[j]\n",
    "        secondName = secondPath.split('/')[-1].split('.')[0]\n",
    "        score = SequenceMatcher(None, firstName, secondName).ratio()\n",
    "        simNameList.append((firstPath, secondPath, score))\n",
    "        \n",
    "simNameList = sorted(simNameList, key = lambda x: x[2], reverse = True)\n",
    "\n",
    "print(\"identical filenames: \" + str(len([i for i in simList if i[2] == 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WRITE SIMILARITY FILE\n",
    "\n",
    "numEntries = 1000\n",
    "\n",
    "with open('/Users/mettinger/Desktop/similarList.txt', 'w') as f:\n",
    "    for item in simList[0:numEntries]:\n",
    "        f.write(\"%s\\n\" % item[0])\n",
    "        f.write(\"%s\\n\" % item[1])\n",
    "        f.write(\"%s\\n\" % str(item[2]))\n",
    "        f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE MAPPING FROM ALL ANNIKA FILES BACK TO 2018_AS DIRECTORY STRUCTURE\n",
    "\n",
    "annikaDictPicklePath = '/Users/mettinger/Data/rockArtProject/annikaDict.pkl'\n",
    "\n",
    "try:\n",
    "    annikaDict = pickle.load(annikaDictPicklePath)\n",
    "except:\n",
    "    allDocFilesGlob = \"/Users/mettinger/Desktop/2018_AS/**/*.docx\"\n",
    "    allFilesDocx = glob.glob(allDocFilesGlob, recursive=True)\n",
    "\n",
    "    numFile = len(allFilesDocx)\n",
    "    annikaFileList = []\n",
    "\n",
    "    for i,filePath in enumerate(allFilesDocx):\n",
    "        fileName = filePath.split(\"/\")[-1]\n",
    "        index = str(int( (i * 10) / numFile))\n",
    "        destPath = \"/Users/mettinger/Desktop/rockArt/original/anikaDocx\" + index + \"/\" + fileName\n",
    "        annikaFileList.append((destPath, filePath))\n",
    "\n",
    "    annikaDict = dict(annikaFileList)\n",
    "    pickle.dump( annikaDict, open( annikaDictPicklePath, \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/mettinger/Desktop/rockArt/original/anikaDocx3/A179-Asia-Indus-Harappa-Bajaur Valley-Priestess-2800-2600 BCE.docx',\n",
       " '/Users/mettinger/Desktop/rockArt/original/anikaDocx8/~$00-AM,S-Peru-Moche-Jaguar Shaman on Gooseback-Ceramic-100-700 CE.docx',\n",
       " '/Users/mettinger/Desktop/rockArt/original/anikaDocx6/~$00-Afr-Mali-Dogon-Nyérum-Female Water Spirit on a Stool.docx',\n",
       " '/Users/mettinger/Desktop/rockArt/original/anikaDocx6/Afr-Sierra Leone-Nommo-Ruetimeyer-1901 Final.docx']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK FOR BAD FILES WITHOUT ANNIKA MAPPING\n",
    "\n",
    "allCurrentGlob = \"/Users/mettinger/Desktop/rockArt/original/**/*.docx\"\n",
    "allFiles = glob.glob(allCurrentGlob, recursive=True)\n",
    "\n",
    "badFiles = []\n",
    "for filePath in allFiles:\n",
    "    if filePath not in annikaDict:\n",
    "        badFiles.append(filePath)\n",
    "\n",
    "badFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annika dict error: /Users/mettinger/Desktop/rockArt/original/anikaDocx3/A179-Asia-Indus-Harappa-Bajaur Valley-Priestess-2800-2600 BCE.docx\n",
      "Annika dict error: /Users/mettinger/Desktop/rockArt/original/anikaDocx8/~$00-AM,S-Peru-Moche-Jaguar Shaman on Gooseback-Ceramic-100-700 CE.docx\n",
      "Annika dict error: /Users/mettinger/Desktop/rockArt/original/anikaDocx6/~$00-Afr-Mali-Dogon-Nyérum-Female Water Spirit on a Stool.docx\n",
      "Annika dict error: /Users/mettinger/Desktop/rockArt/original/anikaDocx6/Afr-Sierra Leone-Nommo-Ruetimeyer-1901 Final.docx\n"
     ]
    }
   ],
   "source": [
    "# RECREATE 2018_AS structure\n",
    "\n",
    "allCurrentGlob = \"/Users/mettinger/Desktop/rockArt/original/**/*.docx\"\n",
    "allFiles = glob.glob(allCurrentGlob, recursive=True)\n",
    "\n",
    "for thisFile in allFiles:\n",
    "    if thisFile in annikaDict:\n",
    "        destination = annikaDict[thisFile]\n",
    "        destination = destination.replace('2018_AS','2018_AS_Processed')\n",
    "        if not os.path.exists(os.path.dirname(destination)):\n",
    "            os.makedirs(os.path.dirname(destination))\n",
    "        shutil.copyfile(thisFile, destination)\n",
    "    else:\n",
    "        print(\"Annika dict error: \" + thisFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
